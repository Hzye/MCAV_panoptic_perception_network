{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from utils import bbox_iou\n",
    "from dataset import DetectionDataset, Normalise, Pad, ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [92.11938007161459, 102.83839236762152, 104.90335580512152]\n",
    "std = [66.09941202519124, 70.6808655565459, 75.05305001603533]\n",
    "\n",
    "## load custom dataset + transforms\n",
    "transformed_train_data = DetectionDataset(\n",
    "    label_dict=\"det_train_shortened.json\",\n",
    "    root_dir='images/',\n",
    "    classes_file=\"data/bdd100k.names\",\n",
    "    grid_sizes=[13, 26, 52],\n",
    "    anchors = np.array([\n",
    "            [[116,90], [156,198], [373,326]],\n",
    "            [[30, 61], [62, 45], [59,119]],\n",
    "            [[10, 13], [16, 30], [33, 23]],\n",
    "        ]),\n",
    "    transform=transforms.Compose([\n",
    "        Normalise(\n",
    "            mean=mean,\n",
    "            std=std\n",
    "        ),\n",
    "        Pad(416),\n",
    "        ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "# separate into batches\n",
    "train_loader = DataLoader(\n",
    "    transformed_train_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10647, 17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    image, labels = data.values()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate batch size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10647, 17])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.cat((labels[0], labels[0]), 0).reshape(2, -1, 17)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape to 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21294, 17])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape(-1, 17)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_preds = torch.load(\"ex_tensors/yolo_layer_output_size10647.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 85])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_preds[coco_preds[:,:,4] > 0.9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretend_preds = torch.load(\"ex_tensors/yolo_layer_output_size10647.pt\")[:,:,:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate batch size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10647, 17])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = torch.cat((pretend_preds[0], pretend_preds[0]), 0).reshape(2, -1, 17)\n",
    "# prediction = prediction.reshape(-1,17)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each loss component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4648e-07, 2.7254e-08, 9.5856e-09,  ..., 8.5092e-06, 7.8421e-08,\n",
       "         2.4701e-08]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretend_preds[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(355.5738)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = labels[:,:,4]*torch.log(pretend_preds[:,:,4])\n",
    "t2 = (1 - labels[:,:,4])*torch.log(1 - pretend_preds[:,:,4])\n",
    "-torch.sum(t1 + t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2275e+09)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mse = torch.square(prediction[:,:,0] - labels[:,:,0])\n",
    "y_mse = torch.square(prediction[:,:,1] - labels[:,:,1])\n",
    "torch.sum(x_mse + y_mse)/prediction.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_i = (labels[:,:,4] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(250.8586)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.sum(obj_i*torch.sum(labels[:,:,-12:]*torch.log(pretend_preds[:,:,-12:]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(250.8586)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.sum(labels[:,:,-12:]*torch.log(pretend_preds[:,:,-12:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj_ij = 1 if\n",
    "- there is an obj in cell i \n",
    "- confidence of predictor j of this cell is highest among all predictors of this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10647])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = prediction[:,:,4]\n",
    "confs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3549, 3])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.reshape(2, -1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 2, 0, 0],\n",
       "        [0, 0, 0,  ..., 2, 0, 0]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_conf = torch.argmax(confs.reshape(2, -1, 3), axis=2)\n",
    "highest_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False],\n",
       "         [ True, False, False],\n",
       "         [ True, False, False],\n",
       "         ...,\n",
       "         [False, False,  True],\n",
       "         [ True, False, False],\n",
       "         [ True, False, False]],\n",
       "\n",
       "        [[ True, False, False],\n",
       "         [ True, False, False],\n",
       "         [ True, False, False],\n",
       "         ...,\n",
       "         [False, False,  True],\n",
       "         [ True, False, False],\n",
       "         [ True, False, False]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.arange(confs.reshape(2, -1, 3).size(2)).reshape(1, 1, -1) == highest_conf.unsqueeze(2)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10647])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.reshape(2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = (labels[:,:,4] == 1)*mask.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "noobj = (labels[:,:,4] == 0)*mask.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mse = torch.square(prediction[:,:,0] - labels[:,:,0])\n",
    "y_mse = torch.square(prediction[:,:,1] - labels[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4550e+09)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x_mse+y_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(138753.9219)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((x_mse+y_mse)*obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1696083.5000)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_mse = torch.square(torch.sqrt(prediction[:,:,2]) - torch.sqrt(labels[:,:,2]))\n",
    "h_mse = torch.square(torch.sqrt(prediction[:,:,3]) - torch.sqrt(labels[:,:,3]))\n",
    "torch.sum(w_mse + h_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31479.4844)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((w_mse*h_mse)*obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = labels[:,:,4]*torch.log(prediction[:,:,4])\n",
    "t2 = (1 - labels[:,:,4])*torch.log(1 - prediction[:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(535.5921)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.sum(t1+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91.4740)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.sum(noobj*(t1+t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(146.5062)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.sum(obj*(t1+t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # lambda constants\n",
    "        self.lambda_class = 1\n",
    "        self.lambda_noobj = 5\n",
    "        self.lambda_box = 5\n",
    "        self.lambda_obj = 1\n",
    "\n",
    "\n",
    "    def forward(self, prediction, label):\n",
    "        \"\"\"\n",
    "        Computes difference between prediction and label.\n",
    "        \n",
    "        Input:\n",
    "        =prediction=    Tensor of all prediction arrays of size (n_batches, 10647, 5+n_classes).\n",
    "        =label=         Tensor of all label arryays of size (n_batches, 10647, 5+n_classes).\n",
    "        \n",
    "        Output:\n",
    "        =loss=          Total loss computed for this batch.\n",
    "        \"\"\"\n",
    "        batch_size = prediction.shape[0]\n",
    "\n",
    "        # I^obj_i in paper\n",
    "        # mask for actual object in grid\n",
    "        obj_i = (label[:,:,4] == 1) # size (batch_size, 10647)\n",
    "\n",
    "        # I^obj_ij in paper\n",
    "        # mask for when there IS obj in label AND box has highest conf score\n",
    "        confs = prediction[:,:,4].reshape(batch_size, -1, 3) # reshape to easily find argmax(box1,box2,box3)\n",
    "        highest_conf = torch.argmax(confs.reshape(batch_size, -1, 3), axis=2)\n",
    "        mask = torch.arange(confs.reshape(batch_size, -1, 3).size(2)).reshape(1, 1, -1) == highest_conf.unsqueeze(2) # create T/F mask\n",
    "        mask = mask.reshape(batch_size, -1) # reshape back to (batch_size, 10647)\n",
    "        # now AND with (there is object) mask\n",
    "        obj_ij = mask*obj_i # size (batch_size, 10647)\n",
    "\n",
    "        # I^noobj_ij in paper\n",
    "        noobj_i = (label[:,:,4] == 0) # true if there are no objects, size (batch_size, 10647)\n",
    "        noobj_ij = mask*noobj_i # size (batch_size, 10647)\n",
    "\n",
    "        ## box loss\n",
    "        # use generic square diff loss (mse)\n",
    "        x_mse = torch.square(prediction[:,:,0] - label[:,:,0])\n",
    "        y_mse = torch.square(prediction[:,:,1] - label[:,:,1])\n",
    "        bbox_centre_mse = x_mse + y_mse\n",
    "        bbox_centre_loss = torch.sum(obj_ij*bbox_centre_mse)\n",
    "\n",
    "        w_mse = torch.square(torch.sqrt(prediction[:,:,2]) - torch.sqrt(label[:,:,2]))\n",
    "        h_mse = torch.square(torch.sqrt(prediction[:,:,3]) - torch.sqrt(label[:,:,3]))\n",
    "        bbox_dims_mse = w_mse + h_mse\n",
    "        bbox_dims_loss = torch.sum(obj_ij*bbox_dims_mse)\n",
    "\n",
    "        bbox_loss = (1/batch_size)*(bbox_centre_loss + bbox_dims_loss)\n",
    "\n",
    "        ## object loss\n",
    "        # use binary cross entropy loss\n",
    "        t1 = label[:,:,4]*torch.log(prediction[:,:,4])\n",
    "        t2 = (1 - label[:,:,4])*torch.log(1 - prediction[:,:,4])\n",
    "        obj_bce = t1 + t2\n",
    "        obj_loss = -(1/batch_size)*torch.sum(obj_ij*obj_bce)\n",
    "\n",
    "        ## no object loss\n",
    "        noobj_loss = -(1/batch_size)*torch.sum(noobj_ij*obj_bce)\n",
    "\n",
    "        ## class loss\n",
    "        # use cross entropy loss\n",
    "        class_loss = -torch.sum(obj_i*torch.sum(label[:,:,-12:]*torch.log(prediction[:,:,-12:]), axis=2))\n",
    "\n",
    "        loss = self.lambda_box*bbox_loss + self.lambda_obj*obj_loss + self.lambda_noobj*noobj_loss + self.lambda_class*class_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, prediction, label, anchors):\n",
    "    \"\"\"\n",
    "    Computes difference between prediction and label.\n",
    "    \n",
    "    Input:\n",
    "    =prediction=    Tensor of all prediction arrays of size (n_batches, 10647, 5+n_classes).\n",
    "    =label=         Tensor of all label arryays of size (n_batches, 10647, 5+n_classes).\n",
    "    \n",
    "    Output:\n",
    "    =loss=          Total loss computed for this batch.\n",
    "    \"\"\"\n",
    "    # check objectness for identity function - 4th ix in labels and predictions\n",
    "    obj = (label[:,:,4] == 1) # I^obj_ij\n",
    "    noobj = (label[:,:,4] == 0) # I^noobj_ij\n",
    "\n",
    "    ## box coordinate loss\n",
    "    prediction[None] = self.sigmoid(prediction[None]) # currently x,y coords\n",
    "    label[None] = torch.log((1e-16 + label[None]/anchors)) # width and height coords\n",
    "    bbox_coord_loss = self.mse(prediction[None][obj], label[None][obj])\n",
    "\n",
    "    ## object loss\n",
    "    anchors = anchors.reshape(1,3,1,1,2)\n",
    "    box_preds = torch.cat([self.sigmoid(prediction[None]), torch.exp(prediction[None])*anchors], dim=-1)\n",
    "    result = bbox_iou(box_preds[obj], label[None][obj]).detach()\n",
    "    obj_loss = self.mse(self.sigmoid(prediction[None][obj]), result*label[None][obj])\n",
    "\n",
    "    ## no object loss\n",
    "    noobj_loss = self.bcwell((prediction[None][noobj]), (label[None][noobj]))\n",
    "\n",
    "    ## class loss\n",
    "    class_loss = self.cross_entropy((prediction[None][obj]), (label[None][obj].long()))\n",
    "\n",
    "    loss = self.lambda_box*bbox_coord_loss + self.lambda_obj*obj_loss + self.lambda_noobj*noobj_loss + self.lambda_class*class_loss\n",
    "\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c07979281c39b40b76a816f18a9a1b4cb65f739279c2f8cf445d62be12adec4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
