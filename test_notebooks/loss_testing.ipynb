{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from utils import bbox_iou\n",
    "from dataset import DetectionDataset, Normalise, Pad, ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [92.11938007161459, 102.83839236762152, 104.90335580512152]\n",
    "std = [66.09941202519124, 70.6808655565459, 75.05305001603533]\n",
    "\n",
    "## load custom dataset + transforms\n",
    "transformed_train_data = DetectionDataset(\n",
    "    label_dict=\"det_train_shortened.json\",\n",
    "    root_dir='images/',\n",
    "    classes_file=\"data/bdd100k.names\",\n",
    "    grid_sizes=[13, 26, 52],\n",
    "    anchors = np.array([\n",
    "            [[116,90], [156,198], [373,326]],\n",
    "            [[30, 61], [62, 45], [59,119]],\n",
    "            [[10, 13], [16, 30], [33, 23]],\n",
    "        ]),\n",
    "    transform=transforms.Compose([\n",
    "        Normalise(\n",
    "            mean=mean,\n",
    "            std=std\n",
    "        ),\n",
    "        Pad(416),\n",
    "        ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "# separate into batches\n",
    "train_loader = DataLoader(\n",
    "    transformed_train_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10647, 17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    image, labels = data.values()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate batch size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10647, 17])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.cat((labels[0], labels[0]), 0).reshape(2, -1, 17)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape to 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21294, 17])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape(-1, 17)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretend_preds = torch.load(\"ex_tensors/yolo_layer_output_size10647.pt\")[:,:,:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate batch size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10647, 17])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = torch.cat((pretend_preds[0], pretend_preds[0]), 0).reshape(2, -1, 17)\n",
    "# prediction = prediction.reshape(-1,17)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing each loss component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4648e-07, 2.7254e-08, 9.5856e-09,  ..., 8.5092e-06, 7.8421e-08,\n",
       "         2.4701e-08]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretend_preds[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(355.5738)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = labels[:,:,4]*torch.log(pretend_preds[:,:,4])\n",
    "t2 = (1 - labels[:,:,4])*torch.log(1 - pretend_preds[:,:,4])\n",
    "-torch.sum(t1 + t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2275e+09)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mse = torch.square(prediction[:,:,0] - labels[:,:,0])\n",
    "y_mse = torch.square(prediction[:,:,1] - labels[:,:,1])\n",
    "torch.sum(x_mse + y_mse)/prediction.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # losses and functions\n",
    "        self.bcwell = nn.BCEWithLogitsLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # lambda constants\n",
    "        self.lambda_class = 1\n",
    "        self.lambda_noobj = 10\n",
    "        self.lambda_box = 10\n",
    "        self.lambda_obj = 1\n",
    "\n",
    "\n",
    "    def forward(self, prediction, label):\n",
    "        \"\"\"\n",
    "        Computes difference between prediction and label.\n",
    "        \n",
    "        Input:\n",
    "        =prediction=    Tensor of all prediction arrays of size (n_batches, 10647, 5+n_classes).\n",
    "        =label=         Tensor of all label arryays of size (n_batches, 10647, 5+n_classes).\n",
    "        \n",
    "        Output:\n",
    "        =loss=          Total loss computed for this batch.\n",
    "        \"\"\"\n",
    "        batch_size = prediction.shape[0]\n",
    "        # check objectness for identity function - 4th ix in labels and predictions\n",
    "        obj = (label[:,:,4] == 1) # I^obj_ij\n",
    "        noobj = (label[:,:,4] == 0) # I^noobj_ij\n",
    "\n",
    "        ## box loss\n",
    "        # use generic square diff loss (mse)\n",
    "        x_mse = torch.square(prediction[:,:,0] - label[:,:,0])\n",
    "        y_mse = torch.square(prediction[:,:,1] - label[:,:,1])\n",
    "        bbox_centre_loss = torch.sum(x_mse + y_mse)\n",
    "\n",
    "        w_mse = torch.square(torch.sqrt(prediction[:,:,2]) - torch.sqrt(label[:,:,2]))\n",
    "        h_mse = torch.square(torch.sqrt(prediction[:,:,3]) - torch.sqrt(label[:,:,3]))\n",
    "        bbox_dims_loss = torch.sum(w_mse + h_mse)\n",
    "\n",
    "        bbox_loss = (1/batch_size)*(bbox_centre_loss + bbox_dims_loss)\n",
    "\n",
    "        ## object loss\n",
    "        # use binary cross entropy loss\n",
    "        t1 = label[:,:,4]*torch.log(prediction[:,:,4])\n",
    "        t2 = (1 - label[:,:,4])*torch.log(1 - prediction[:,:,4])\n",
    "        obj_loss = -(1/batch_size)*torch.sum(t1 + t2)\n",
    "\n",
    "        ## no object loss\n",
    "        noobj_loss = self.bcwell((prediction[None][noobj]), (label[None][noobj]))\n",
    "\n",
    "        ## class loss\n",
    "        class_loss = self.cross_entropy((prediction[None][obj]), (label[None][obj].long()))\n",
    "\n",
    "        loss = self.lambda_box*bbox_loss + self.lambda_obj*obj_loss + self.lambda_noobj*noobj_loss + self.lambda_class*class_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, prediction, label, anchors):\n",
    "    \"\"\"\n",
    "    Computes difference between prediction and label.\n",
    "    \n",
    "    Input:\n",
    "    =prediction=    Tensor of all prediction arrays of size (n_batches, 10647, 5+n_classes).\n",
    "    =label=         Tensor of all label arryays of size (n_batches, 10647, 5+n_classes).\n",
    "    \n",
    "    Output:\n",
    "    =loss=          Total loss computed for this batch.\n",
    "    \"\"\"\n",
    "    # check objectness for identity function - 4th ix in labels and predictions\n",
    "    obj = (label[:,:,4] == 1) # I^obj_ij\n",
    "    noobj = (label[:,:,4] == 0) # I^noobj_ij\n",
    "\n",
    "    ## box coordinate loss\n",
    "    prediction[None] = self.sigmoid(prediction[None]) # currently x,y coords\n",
    "    label[None] = torch.log((1e-16 + label[None]/anchors)) # width and height coords\n",
    "    bbox_coord_loss = self.mse(prediction[None][obj], label[None][obj])\n",
    "\n",
    "    ## object loss\n",
    "    anchors = anchors.reshape(1,3,1,1,2)\n",
    "    box_preds = torch.cat([self.sigmoid(prediction[None]), torch.exp(prediction[None])*anchors], dim=-1)\n",
    "    result = bbox_iou(box_preds[obj], label[None][obj]).detach()\n",
    "    obj_loss = self.mse(self.sigmoid(prediction[None][obj]), result*label[None][obj])\n",
    "\n",
    "    ## no object loss\n",
    "    noobj_loss = self.bcwell((prediction[None][noobj]), (label[None][noobj]))\n",
    "\n",
    "    ## class loss\n",
    "    class_loss = self.cross_entropy((prediction[None][obj]), (label[None][obj].long()))\n",
    "\n",
    "    loss = self.lambda_box*bbox_coord_loss + self.lambda_obj*obj_loss + self.lambda_noobj*noobj_loss + self.lambda_class*class_loss\n",
    "\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c07979281c39b40b76a816f18a9a1b4cb65f739279c2f8cf445d62be12adec4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
